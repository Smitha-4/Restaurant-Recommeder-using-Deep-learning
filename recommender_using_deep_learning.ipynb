{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT-hcJKitBih"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Concatenate, Input, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "class RestaurantRecommender:\n",
        "    def __init__(self):\n",
        "        self.le = LabelEncoder()\n",
        "        self.ohe = OneHotEncoder(sparse=False)\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.model = None\n",
        "\n",
        "    def preprocess_data(self, df):\n",
        "        # Encode categorical features\n",
        "        df['location_encoded'] = self.le.fit_transform(df['location'])\n",
        "        df['cuisines_encoded'] = self.le.fit_transform(df['cuisines'])\n",
        "        df['rest_type_encoded'] = self.le.fit_transform(df['rest_type'])\n",
        "\n",
        "        # One-hot encode price range\n",
        "        price_encoded = self.ohe.fit_transform(df['price'].values.reshape(-1, 1))\n",
        "        df = pd.concat([df, pd.DataFrame(price_encoded, columns=self.ohe.categories_[0])], axis=1)\n",
        "\n",
        "        # Create user and item IDs\n",
        "        user_ids = df['user_id'].unique()\n",
        "        self.user_id_map = {u: i for i, u in enumerate(user_ids)}\n",
        "        df['user_id_encoded'] = df['user_id'].map(self.user_id_map)\n",
        "\n",
        "        item_ids = df['restaurant_id'].unique()\n",
        "        self.item_id_map = {i: j for j, i in enumerate(item_ids)}\n",
        "        df['item_id_encoded'] = df['restaurant_id'].map(self.item_id_map)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_user_input(self, user_input):\n",
        "        # Clean and preprocess user input text\n",
        "        tokens = word_tokenize(user_input.lower())\n",
        "        filtered_tokens = [word for word in tokens if word not in self.stop_words and word.isalpha()]\n",
        "        lemmatized_tokens = [self.lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "        processed_input = ' '.join(lemmatized_tokens)\n",
        "        return processed_input\n",
        "\n",
        "    def build_model(self, num_users, num_items, embedding_dim=50, hidden_units=[128, 64], dropout_rate=0.2):\n",
        "        # Create the model\n",
        "        model = Sequential()\n",
        "\n",
        "        # User embedding\n",
        "        model.add(Embedding(num_users, embedding_dim, input_shape=(1,)))\n",
        "        model.add(Flatten())\n",
        "\n",
        "        # Item embedding\n",
        "        model.add(Embedding(num_items, embedding_dim, input_shape=(1,)))\n",
        "        model.add(Flatten())\n",
        "\n",
        "        # Concatenate user, item, and categorical features\n",
        "        model.add(Concatenate(axis=1))\n",
        "\n",
        "        # Add dense layers\n",
        "        for units in hidden_units:\n",
        "            model.add(Dense(units, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "        # Output layer\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train_model(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
        "        self.model = self.build_model(len(self.user_id_map), len(self.item_id_map))\n",
        "        self.model.fit(X_train.values, y_train.values, epochs=epochs, batch_size=batch_size, validation_data=(X_test.values, y_test.values))\n",
        "        self.model.save('restaurant_recommender_model.h5')\n",
        "\n",
        "    def predict(self, user_id, item_id, features):\n",
        "        user_encoded = self.user_id_map[user_id]\n",
        "        item_encoded = self.item_id_map[item_id]\n",
        "        input_data = [user_encoded, item_encoded] + list(features)\n",
        "        input_data = np.array(input_data).reshape(1, -1)\n",
        "        prediction = self.model.predict(input_data)\n",
        "        return prediction[0][0]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    df = pd.read_csv(\"cleaned_file.csv\")  # Replace with your data file\n",
        "    recommender = RestaurantRecommender()\n",
        "    df = recommender.preprocess_data(df)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X = df[['user_id_encoded', 'item_id_encoded', 'location_encoded', 'cuisines_encoded', 'rest_type_encoded', 'cheap', 'moderate', 'fine-dining']]\n",
        "    y = df['rating']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    recommender.train_model(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Make a prediction\n",
        "    user_id = 'user123'\n",
        "    item_id = 'restaurant_abc'\n",
        "    features = [1, 2, 3, 0, 1, 0]  # Example feature values\n",
        "    predicted_rating = recommender.predict(user_id, item_id, features)\n",
        "    print(f\"Predicted rating for user {user_id} and item {item_id}: {predicted_rating}\")"
      ]
    }
  ]
}